{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "WhJlgAHsWlyk"
      },
      "outputs": [],
      "source": [
        "# importng the libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing LeNet architecture\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet,self).__init__()  # make our custom class LeNet to inherit __init__ of nn.module\n",
        "    self.relu=F.relu\n",
        "    self.pool=nn.AvgPool2d(kernel_size=(2,2))\n",
        "    self.conv1=nn.Conv2d(in_channels=1,out_channels=6,kernel_size=(5,5),stride=1,padding=0) #padding:0 ==> no padding , padding:1 ==> 'same'\n",
        "    self.conv2=nn.Conv2d(in_channels=6,out_channels=16,kernel_size=(5,5),stride=1,padding=0)\n",
        "    self.conv3=nn.Conv2d(in_channels=16,out_channels=120,kernel_size=(5,5),stride=1,padding=0)\n",
        "    self.linear1=nn.Linear(120,84)\n",
        "    self.linear2=nn.Linear(84,10)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.relu(self.conv1(x))\n",
        "    x=self.pool(x)\n",
        "    x=self.relu(self.conv2(x))\n",
        "    x=self.pool(x)\n",
        "    x=self.relu(self.conv3(x))\n",
        "    # reshaping  batchsize X 120 X 1 X 1 ====> batchsize X 120\n",
        "    x=x.reshape(x.shape[0],-1)\n",
        "    x=self.relu(self.linear1(x))\n",
        "    x=self.linear2(x)\n",
        "    return x\n",
        "\n",
        "  def evaluate(self,loader):\n",
        "    num_samples=0\n",
        "    num_correct=0\n",
        "    # setting model to evaluation mode  #Batch normalization layers behave differently during training and evaluation. During training, they use batch statistics for normalization, but during evaluation, they use population statistics.Dropout layers also behave differently during training and evaluation. During training, they randomly drop units, but during evaluation, they keep all units and adjust the weights accordingly.model.eval() sets the model to evaluation mode, which ensures that batch normalization and dropout layers behave in the appropriate way during inference.\n",
        "    self.eval()\n",
        "    # we don't want to compute gradients while evaluating\n",
        "    with torch.no_grad():\n",
        "      for x,y_true in loader:\n",
        "        # moving x and y to the CPU\n",
        "        x=x.to(device='cpu')\n",
        "        y_true=y_true.to(device='cpu')\n",
        "        logits=self(x)\n",
        "        # getting labels\n",
        "        _,y_pred=logits.max(dim=1)\n",
        "        num_correct+=(y_pred==y_true).sum()\n",
        "        num_samples+=y_pred.size(0)\n",
        "        # computing the accurcy\n",
        "      accuracy=float(num_correct)/float(num_samples)\n",
        "      # assert(accuracy==float)\n",
        "    # print(f\"The accuracy is {accuracy}\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "hODOHX95XPRt"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the transforms to be made\n",
        "transformations=transforms.Compose(\n",
        "    [\n",
        "     transforms.Pad(padding=2,fill=0,padding_mode='constant'),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.1307,), (0.3081,))\n",
        "     ]\n",
        "    )"
      ],
      "metadata": {
        "id": "uL8jrQjNXPwQ"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the training data\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True,transform=transformations)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "VZ4U22FfJOfj"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the test data\n",
        "testset=torchvision.datasets.MNIST(root='./data',train=False,download=True,transform=transformations)\n",
        "testloader=torch.utils.data.DataLoader(testset,batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "hLTf54fPLROs"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definfing the model\n",
        "model=LeNet()\n",
        "# definging the optimzer\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
        "# definfing the loss function\n",
        "loss_func=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "27n5BVh_O-Dn"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "num_epochs=5\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for batch_idx,(data,target) in enumerate(trainloader):\n",
        "\n",
        "    # each batch starts from fresh gradients so zeroing out the gradient for each batch\n",
        "    optimizer.zero_grad()\n",
        "    # forward prop\n",
        "    outputs=model(data)\n",
        "    # calculating the loss\n",
        "    loss=loss_func(outputs,target)\n",
        "    # backprop\n",
        "    loss.backward()\n",
        "    # updating the parameters\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}\\t Accuracy:{model.evaluate(testloader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiB4LiQtPgvl",
        "outputId": "fa7d8f1a-13b8-4374-97af-d247a859086b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\t Accuracy:0.974\n",
            "Epoch 2\t Accuracy:0.9837\n",
            "Epoch 3\t Accuracy:0.9833\n",
            "Epoch 4\t Accuracy:0.9878\n",
            "Epoch 5\t Accuracy:0.9882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "et8Vgt72WHWp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}